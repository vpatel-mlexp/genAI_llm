{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 03:40:55 WARNING mlflow.tracking.client: Failed to start trace RunnableSequence: API request to endpoint /api/2.0/mlflow/traces failed with error code 404 != 200. Response body: ''. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nMLflow is an open-source platform for managing the entire machine learning lifecycle. It helps data scientists and machine learning engineers track and reproduce experiments, package and deploy models, and collaborate with other team members. It also provides a centralized repository for storing and organizing models, making it easier to track and compare model performance. Overall, MLflow aims to streamline and simplify the process of building, testing, and deploying machine learning models.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import mlflow\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'vivekpatel.iitp'  \n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'Patelvivek007' \n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'https://dagshub.com/vivekpatel.iitp/genAI_llm.mlflow' \n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"GenAI\")\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Ensure that the \"OPENAI_API_KEY\" environment variable is set\n",
    "llm = OpenAI()\n",
    "prompt = PromptTemplate.from_template(\"Answer the following question: {question}\")\n",
    "chain = prompt | llm\n",
    "\n",
    "# Invoking the chain will cause a trace to be logged\n",
    "chain.invoke(\"What is MLflow?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
